{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_hezpew4yME"
      },
      "source": [
        "Horizontal camera position"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tF-iNnbM4vRf"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Function to find the X-coordinate of colored objects\n",
        "def find_x_coordinate(frame):\n",
        "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    inverted_gray_frame = cv2.bitwise_not(gray_frame)\n",
        "    _, mask = cv2.threshold(inverted_gray_frame, 50, 255, cv2.THRESH_BINARY)\n",
        "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    x_coordinates = []\n",
        "\n",
        "    for contour in contours:\n",
        "        if cv2.contourArea(contour) > 500:\n",
        "            moments = cv2.moments(contour)\n",
        "            if moments[\"m00\"] != 0:\n",
        "                cx = int(moments[\"m10\"] / moments[\"m00\"])\n",
        "                x_coordinates.append(cx)\n",
        "\n",
        "    return x_coordinates\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    x_coords = find_x_coordinate(frame)\n",
        "\n",
        "    for cx in x_coords:\n",
        "        print(f\"X-coordinate of the object: {cx}\")\n",
        "\n",
        "    cv2.imshow(\"Frame\", frame)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2X7VdALx6auV"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UC03bBVI449r"
      },
      "source": [
        "Vertical camera position"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEMMGVXU47FY"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Function to find the Y-coordinate of colored objects\n",
        "def find_y_coordinate(frame):\n",
        "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    inverted_gray_frame = cv2.bitwise_not(gray_frame)\n",
        "    _, mask = cv2.threshold(inverted_gray_frame, 50, 255, cv2.THRESH_BINARY)\n",
        "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    y_coordinates = []\n",
        "\n",
        "    for contour in contours:\n",
        "        if cv2.contourArea(contour) > 500:\n",
        "            moments = cv2.moments(contour)\n",
        "            if moments[\"m00\"] != 0:\n",
        "                cy = int(moments[\"m01\"] / moments[\"m00\"])\n",
        "                y_coordinates.append(cy)\n",
        "\n",
        "    return y_coordinates\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    y_coords = find_y_coordinate(frame)\n",
        "\n",
        "    for cy in y_coords:\n",
        "        print(f\"Y-coordinate of the object: {cy}\")\n",
        "\n",
        "    cv2.imshow(\"Frame\", frame)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yz3IlBx46cDQ"
      },
      "source": [
        "Code that handles both vertical and horizontal camera positions, returning the Y or X coordinates of the detected colored object based on the camera's orientation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJQN8mTf6gHG"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Function to find the coordinates of colored objects\n",
        "def find_colored_object_coordinates(frame, lower_color, upper_color, axis='both'):\n",
        "    # Convert the frame to HSV color space\n",
        "    hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Apply Gaussian Blur to the frame to reduce noise\n",
        "    blurred_frame = cv2.GaussianBlur(hsv_frame, (11, 11), 0)\n",
        "\n",
        "    # Create a mask for the specified color\n",
        "    mask = cv2.inRange(blurred_frame, lower_color, upper_color)\n",
        "\n",
        "    # Apply morphological operations to remove small noise and close gaps in the mask\n",
        "    mask = cv2.erode(mask, None, iterations=2)\n",
        "    mask = cv2.dilate(mask, None, iterations=2)\n",
        "\n",
        "    # Find contours in the mask\n",
        "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    coordinates = []\n",
        "\n",
        "    for contour in contours:\n",
        "        if cv2.contourArea(contour) > 500:  # Filter small contours\n",
        "            # Get the moments to calculate the centroid\n",
        "            moments = cv2.moments(contour)\n",
        "            if moments[\"m00\"] != 0:\n",
        "                cx = int(moments[\"m10\"] / moments[\"m00\"])\n",
        "                cy = int(moments[\"m01\"] / moments[\"m00\"])\n",
        "\n",
        "                if axis == 'both':\n",
        "                    coordinates.append((cx, cy))\n",
        "                elif axis == 'x':\n",
        "                    coordinates.append(cx)\n",
        "                elif axis == 'y':\n",
        "                    coordinates.append(cy)\n",
        "\n",
        "                # Draw the contour and centroid on the frame\n",
        "                cv2.drawContours(frame, [contour], -1, (0, 255, 0), 2)\n",
        "                cv2.circle(frame, (cx, cy), 5, (0, 0, 255), -1)\n",
        "\n",
        "    return coordinates\n",
        "\n",
        "# Define the color range for detection (HSV values)\n",
        "lower_color = np.array([100, 150, 0])  # Lower bound for blue color\n",
        "upper_color = np.array([140, 255, 255])  # Upper bound for blue color\n",
        "\n",
        "# Function to process the video and print coordinates\n",
        "def process_video(axis):\n",
        "    cap = cv2.VideoCapture(0)\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Find the object coordinates\n",
        "        coords = find_colored_object_coordinates(frame, lower_color, upper_color, axis)\n",
        "\n",
        "        for coord in coords:\n",
        "            if axis == 'x':\n",
        "                print(f\"X-coordinate of the object: {coord}\")\n",
        "            elif axis == 'y':\n",
        "                print(f\"Y-coordinate of the object: {coord}\")\n",
        "            else:\n",
        "                print(f\"Coordinates of the object: {coord}\")\n",
        "\n",
        "        # Display the frame\n",
        "        cv2.imshow(\"Frame\", frame)\n",
        "\n",
        "        # Break the loop if 'q' is pressed\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    # Release the camera and close all OpenCV windows\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "\n",
        "# For both coordinates:\n",
        "process_video(axis='both')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Slanted camera angle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Define the color range for detection (HSV values)\n",
        "lower_color = np.array([30, 150, 50])  # Example: lower bound for green color\n",
        "upper_color = np.array([80, 255, 255])  # Example: upper bound for green color\n",
        "\n",
        "# Define source and destination points for perspective correction\n",
        "# Adjust these points based on your specific camera setup\n",
        "src_points = np.float32([[100, 100], [200, 100], [100, 200], [200, 200]])\n",
        "dst_points = np.float32([[50, 50], [250, 50], [50, 250], [250, 250]])\n",
        "\n",
        "def correct_perspective(frame, src_points, dst_points):\n",
        "    matrix = cv2.getPerspectiveTransform(src_points, dst_points)\n",
        "    corrected_frame = cv2.warpPerspective(frame, matrix, (frame.shape[1], frame.shape[0]))\n",
        "    return corrected_frame\n",
        "\n",
        "def detect_color(frame):\n",
        "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "    mask = cv2.inRange(hsv, lower_color, upper_color)\n",
        "    result = cv2.bitwise_and(frame, frame, mask=mask)\n",
        "    return mask, result\n",
        "\n",
        "def main():\n",
        "    global src_points, dst_points\n",
        "\n",
        "    cap = cv2.VideoCapture(0)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error: Could not open video capture.\")\n",
        "        return\n",
        "\n",
        "    cv2.namedWindow('Webcam Feed')\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            print(\"Error: Could not read frame.\")\n",
        "            break\n",
        "\n",
        "        # Correct the perspective distortion\n",
        "        corrected_frame = correct_perspective(frame, src_points, dst_points)\n",
        "\n",
        "        # Detect the color in the corrected frame\n",
        "        mask, result = detect_color(corrected_frame)\n",
        "\n",
        "        # Find contours of the detected objects\n",
        "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        for contour in contours:\n",
        "            if cv2.contourArea(contour) > 500:  # Adjust the threshold as needed\n",
        "                x, y, w, h = cv2.boundingRect(contour)\n",
        "                center_x = x + w // 2\n",
        "                center_y = y + h // 2\n",
        "                cv2.rectangle(corrected_frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "                cv2.putText(corrected_frame, f'X: {center_x}, Y: {center_y}', (x, y - 10),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "        # Display the frames\n",
        "        cv2.imshow('Webcam Feed', corrected_frame)\n",
        "        cv2.imshow('Mask', mask)\n",
        "        cv2.imshow('Detected Color', result)\n",
        "\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
